#!/bin/bash
#----------------------------------------------------------------
# Cluster disease data names.
# Input: CSV file from Alexandra
# Output: CSV with disease name, clustered disease (to stdout)
# 
# Author: Oren E. Livne
# Date:   11-JUL-2013
#----------------------------------------------------------------
# Read input arguments
DARGS=65
PROGNAME=`basename $0`
in_file="$1"

# Create temporary directory
#tmp="/tmp/${PROGNAME}.$$.tmp"
tmp="/tmp/${PROGNAME}"
mkdir -p ${tmp}

# Pre-process input:
# - Convert Mac newlines
# - Fetch disease names
# - Trim white space; remove underscores
# - Remove "'s" for easier downstream regex matching
# - Create a line index into the original file so that we can correlate the clustered disease
#    names with the original line numbers.
# index.txt - sorted trimmed disease names along with the original line numbers they appear in
# count.txt - sorted unique disease names and their occurrence #s in index.txt
# diseases.txt - sorted unique disease names
cat ${in_file} | tr '\r' '\n' > ${tmp}/input.txt
cut -d, -f 3 ${tmp}/input.txt | sed -e "s/(.*)//g;s/^ *//;s/ *$//;s/'s//g;s/_//g" | nl | sort -t$'\t' -k 2,2 > ${tmp}/index.txt
cut -f 2 ${tmp}/index.txt | uniq -c > ${tmp}/count.txt
cut -f 2 ${tmp}/index.txt | uniq > ${tmp}/diseases.txt
printf "Number of input lines:        %s\n" `wc -l ${tmp}/index.txt | awk '{print $1}'`
printf "Number of unique diseases:    %s\n" `wc -l ${tmp}/count.txt | awk '{print $1}'`

# Cluster the diseases
python ${OBER_CODE}/misc/examples/string_clustering.py < ${tmp}/diseases.txt > ${tmp}/clustered.txt
printf "Number of clustered diseases: %s\n" `tail -1 /tmp/cluster-disease-names/clustered.txt | cut -d, -f 1`

# For each unique disease name, repeat it and its clustered (standardized) names
# the #times it appears in the list of index.txt so that we can match it with index.txt.
# Then join with index.txt and sort in the original line number ordering
paste <(awk '{print $1}' ${tmp}/index.txt) <(paste -d, <(sort -t, -k 2,2 ${tmp}/clustered.txt | cut -d, -f 3) <(awk '{printf "%s,", $1; for (i = 2; i < NF; i++) printf "%s ", $i; printf "%s\n", $NF;}' ${tmp}/count.txt) | awk -F, '{ for (i = 1; i <= $2; i++) { printf "%s,%s\n", $1, $3; } }') | sort -k 1,1n | cut -f 2 | cut -d, -f 1 > ${tmp}/out

paste -d, ${tmp}/input.txt ${tmp}/out
rm -rf ${tmp}
